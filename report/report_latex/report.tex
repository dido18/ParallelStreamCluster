%\documentclass[11pt,a4paper]{article}
\documentclass[12pt]{article}

\usepackage{amsmath,amssymb,wasysym} % per simbolo di spunta\usepackage{amsmath,amssymb,wasysym}

\usepackage{tabularx}
\usepackage{graphicx}
\usepackage{subfig}
\usepackage{booktabs}
\usepackage{caption}
\usepackage{geometry}
\usepackage{pgfplots}
\pgfplotsset{/pgf/number format/use comma,compat=newest}

\setlength\parindent{0pt} % Removes all indentation from paragraphs
\renewcommand{\labelenumi}{\alph{enumi}.} % Make numbering in the enumerate environment by letter rather than number (e.g. section 6)

\title{SPM final project}
\author{Davide Neri}
\date{\today}

\begin{document}
\maketitle    % Insert the title, author and date
\begin{center}
Master Degree in Computer Science and Networking 
A-Y 2015-16

\end{center}

\begin{center}

\begin{tabular}{l r}
Student: & Davide Neri \\ % Date the experiment was performed
Instructor: & Marco Danelutto \\% Instructor/supervisor
Course: & Distributed Systems: Paradigms and models\\
\end{tabular}
\end{center}

\begin{abstract} 
The report describes the final project addressing the \textbf{StreamCluster (SC)} application. The sequential code is provided by \emph{C} code (PARSEC and RODINIA Benchmark Suite). The parallel version is implemented using \textbf{FastFlow} framework (\emph{C++}).
\end{abstract}

\section{Application Analysis}
Given a stream  of points the appicatlion find the a predetermined number od medians.
The points of the stream are organized in chuncks. For every chunk received, the application  computes the intermediate centers in the chunk. When the stream of chunks is finished, the algorithm finds the center points among all the intermediate centers.

The figure~\ref{fig:profile} shows the sequential algorithm profiling with a \texttt{simlarge} imput test. Can be observe that the sequential algorithm spend most of the time evaluating the gain of opening a new center (\texttt{pgain} function). 

\begin{figure}
\center
\includegraphics[scale=0.5]{images/profileSeq.png}
\caption{Profiling with simlarge input (completiom times(s)).}
\label{fig:profile}
\end{figure}


The problem becomes computationally intesitive as the dimensinality of the points increases.
The goal is to parallelize both the processing of different chunks in the stream (that are independent) and the processing of the single chunk. 

\section{Design choice}
A \emph{task-decomposition} pattern is used to model parallel execution of chunks points in the stream. A single chunk computation is parallelized using a \emph{data-decompositon} pattern.

The application doesn't require any particular order of the chunks, because finding the intermediate centers points in different chunks is totally indipendent of the order in wich the chunks arrives. 
Howhewer the results can be different due to the fact that the algorithm use a \texttt{shuffle} procedure that performs a permutation of the points and can changes the final centers. Using a seed is not sufficient to guarantee  equal permutations because each worker is indipendent.


The dependency analysis: different order of the chunks can have different centers computation. In this particular application is not required to have ordered chunks because in any case the results is a set of centers of the points received that can appear in any order in the stream.

The design evaluation :
\begin{itemize}
\item The target platform is a shared memory machine (16 cores on host machine or 240 cores on Xeon phi machine).
\item Is possible to specify different parameters in order to have different parallel version. Is possible to have only the "task-decompositon" or only the "data decomposition" or a combination.
\end{itemize}

The parameters can be tuned for having different possibility:  parallelism degree in the task-farm pattern and map parallel. 

The task-parallelism is used to divide the stream of points in chunks and send the chunks to the workers. 
Each worker is in charge to compute a single chunk of points and find the centers.
Data parallel pattern uses loop parallelism.




\section{Compile,run and tests the project}
the short user manual should be detailed enough to enable me to run tests with your software (what should I compile, how, which are the parameters to use to launch experiments, how can I vary parallelism degree, which input files do I need, where are they)

The structure of the folders are:
\begin{itemize}
\item \texttt{bin/}  : contains the executables (automatic creation during the compilation).
\item \texttt{run/}  : contains the output results (automatic creation during the execution).
\item \texttt{conf/} : contains the parameters of the application (binary path and input parameters).
\item \texttt{src/} : contains the source code.
\item \texttt{streamclusterMgmt.sh} runs different applications with different input on local machine or host.
\item \texttt{upload.sh} uses \textit{rsync} to synchronize the local project on the Phi machine.
\item \texttt{run\_*\_on\_mic.pl} runs the executbales multiple times in the mic0, returning the average completion times  (map : run the map parallel version, farm: runs the farm version).
\end{itemize}

\textbf{Compilation}
For compiling the project is required \textit{cmake 3.x}.
The steps are (starting from the root folder of the project):
\begin{enumerate}
\item \texttt{mkdir build \&\& cd build} creates the build directory and goes inside.
\item \texttt{CXX=icc cmake ..}  compile the executables. Two executables are olso directly copied in the mic0 machine.
\end{enumerate}

\textbf{Run} 
\begin{center}
\texttt{streamclusterMgmt.sh }
\end{center}


\section{Experimantal results}
The executable are runned on \textbf{mic0} machine with 60 cores and 4 contexts.
I have runned three differents inputs for each of the two versions (only data-parallal or task-parallelism).
\begin{itemize}
\item \texttt{simmedium} is a collection of 8192 points with 64 dimensions each.
\item \textit{simlarge} is a collection of 16384 points with 128 dimensions each.
\item \textit{native} is a collection of 1000000 points with 128 dimensions each.
\end{itemize}

\subsection{Data-parallel}

\subsubsection*{scalability}


\begin{tikzpicture}
\begin{axis} [axis lines=middle, xmin=1, xmax=100,  ymin=0, ymax=30, grid=major, xlabel=$Parallelism degree$, ylabel=$Completion time$,
title={Completion time Map}]
\addplot table [col sep=comma] {../../testResults/ff_map.mic.simlarge};
\end{axis}
\end{tikzpicture}


%\begin{figure}
%\centering
%\includegraphics[scale=0.7]{images/activePassive.png}
%\caption{Active and passive thread protocols.}
%\label{fig:activePassive}
%\end{figure}


%\begin{tikzpicture}
%\begin{axis} [axis lines=middle, xmin=1, xmax=16,  ymin=0, ymax=16, grid=major, xlabel=$parallelism$, %ylabel=$scalability$,
%title={Scalability data parallel}]
%\addplot table [col sep=comma] {graphix/fffarmmap.simlarge.data.csv};
%\end{axis}
%\end{tikzpicture}


\begin{thebibliography}{9}

\item
Mark Jelasity, Spyros Voulgaris, Rachid Guerraoui, Anne Marie Kermar-
rec, Maarten van Steen, \emph{Gossip-based peer sampling,} ACM Transaction on
Computer Systems, October 2007.
\end{thebibliography}

\end{document}
